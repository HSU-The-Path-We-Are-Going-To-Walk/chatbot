from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from datetime import datetime
import time

# ğŸ”¹ config.pyì—ì„œ ì „ì—­ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
from config import LLM, DATABASE  

store = {}
session_id = "abc123"
last_interaction_time = time.time() # ë§ˆì§€ë§‰ ì…ë ¥ ì‹œê°„
current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"í˜„ì¬ ë‚ ì§œ ë° ì‹œê°„: {current_date}")

def log_time(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ì„ ë¡œê¹…í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        print(f"â³ {func.__name__} ì‹¤í–‰ ì‹œê°„: {elapsed_time:.4f}ì´ˆ")
        return result
    return wrapper

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œ
def reset_session(session_id: str):
    if session_id in store:
        del store[session_id]
        print("ğŸ”„ ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

def reset_if_idle(timeout=60):
    global last_interaction_time, session_id
    if time.time() - last_interaction_time > timeout:
        reset_session(session_id)
        last_interaction_time = time.time

# Pinecone ê²€ìƒ‰ ì„¤ì • (ì „ì—­ DATABASE ì‚¬ìš©)
def get_retriever():
    search_kwargs = {"k": 2}
    return DATABASE.as_retriever(search_kwargs=search_kwargs)

# LLM ê°€ì ¸ì˜¤ê¸° (ì „ì—­ LLM ì‚¬ìš©)
def get_llm():
    return LLM

# íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ ì„¤ì •
def get_history_retriever():
    retriever = get_retriever()
    
    contextualize_q_system_prompt = (
        "Given a chat history and the latest user question "
        "which might reference context in the chat history, "
        "formulate a standalone question which can be understood "
        "without the chat history. Do NOT answer the question, "
        "just reformulate it if needed and otherwise return it as is"
    )

    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    return create_history_aware_retriever(LLM, retriever, contextualize_q_prompt)

# RAG ì²´ì¸ ìƒì„± (ìµœì´ˆ 1íšŒ ìƒì„± í›„ ì¬ì‚¬ìš©)
def create_rag_chain():
    history_aware_retriever = get_history_retriever()
    
    system_prompt = (
        f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {current_date}ì…ë‹ˆë‹¤.\n"
        "ë‹¹ì‹ ì€ ìš¸ì§„êµ° ë²„ìŠ¤ì •ë¥˜ì¥ì—ì„œ ì–´ë¥´ì‹ ë“¤ê³¼ ëŒ€í™”í•˜ëŠ” ì¹œê·¼í•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
        "ì–´ë¥´ì‹ ë“¤ì´ ì§ˆë¬¸í•˜ê¸° ì „ì— ë¨¼ì € ê´€ì‹¬ì„ í‘œí˜„í•˜ê³ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.\n"
        # "ëŒ€í™”ê°€ ì‹œì‘ë  ë•Œì—ëŠ” ì˜¤ëŠ˜ì€ ì–´ë”” ê°€ì‹œë‚˜ìš”? ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”.\n" -> íŠ¸ë¦¬ê±° ë°œë™ì‹œ ë¨¼ì € ëŒ€í™”í•  ë‚´ìš©
        "ì¶œë ¥ì€ ì˜¤ë””ì˜¤ë¡œ ì œê³µë˜ë¯€ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(ì˜ˆ: `**ê°•ì¡°**`, `- ë¦¬ìŠ¤íŠ¸`, `[ë§í¬](url)`, ````ì½”ë“œ````)ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , í‰ë²”í•œ ì¼ìƒ ëŒ€í™”ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì¥ì„ êµ¬ì„±í•˜ì„¸ìš”."
        "ë²„ìŠ¤ ë„ì°© ì •ë³´ë¥¼ ì œê³µí•  ë•ŒëŠ” ì˜ˆìƒ ë„ì°© ì‹œê°„ì„ ì•Œë ¤ì£¼ê³ , ê³µì§€ì‚¬í•­ì„ ì„¤ëª…í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì¤‘ìš”í•œ ë‚´ìš©ë§Œ ì§§ê²Œ í•œ ì¤„ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
        "ì–´ë ¤ìš´ ë‹¨ì–´ë‚˜ ê¸°ìˆ ì ì¸ í‘œí˜„ì„ í”¼í•˜ê³ , ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
    )

    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
            ("ai", "{context}"),
        ]
    )

    question_answer_chain = create_stuff_documents_chain(LLM, qa_prompt)
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

    return RunnableWithMessageHistory(
        rag_chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
        output_messages_key="answer",
    ).pick('answer')

# âœ… RAG ì²´ì¸ì„ ì „ì—­ìœ¼ë¡œ ì„ ì–¸í•˜ì—¬ ì¬ì‚¬ìš©
RAG_CHAIN = create_rag_chain()

def get_ai_response(user_message, session_id):
    ai_response_stream = RAG_CHAIN.stream(
        {"input": user_message},
        config={"configurable": {"session_id": session_id}},
    )
    return ai_response_stream

def chat():
    global last_interaction_time
    print("ğŸš ìš¸ì§„ AI ì±—ë´‡ ğŸ¤– (ì¢…ë£Œ: 'exit', ì´ˆê¸°í™”: 'reset')")
    
    while True:
        reset_if_idle()
        user_input = input("ğŸ‘¤: ")
        last_interaction_time = time.time() #ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´ ì‹œê°„ ê°±ì‹ 
        if user_input.lower() == "e":
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        elif user_input.lower() == "r":
            reset_session(session_id)
            continue # ìƒˆë¡œìš´ ì…ë ¥ì„ ë°›ë„ë¡ ë°˜ë³µë¬¸ ìœ ì§€

        ai_response = get_ai_response(user_input, session_id)
        print("ğŸ¤–:", end=" ")
        for chunk in ai_response:
            print(chunk, end="", flush=True)
        print()

chat()
